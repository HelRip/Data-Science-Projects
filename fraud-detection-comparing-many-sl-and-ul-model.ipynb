{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hellixir/fraud-detection-comparing-many-sl-and-ul-model?scriptVersionId=182854362\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# <h1 style=\"text-align:center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; color: #007bff;\">CREDIT CARD FRAUD DETECTION</h1>\n\n","metadata":{}},{"cell_type":"markdown","source":"# About this notebook\n\n## Objective\n- The main objective of this notebook is to explore and analyze credit card fraud detection using machine learning techniques. \n- This notebook provides a comprehensive overview of credit card fraud detection, highlighting the strengths and limitations of various machine learning approaches. The insights gained can inform the development of effective fraud detection systems and contribute to the ongoing efforts to mitigate financial fraud risks.\n\n\n## Dataset\nThe dataset used in this analysis is sourced from [Kaggle's Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data). It contains 284,807 instances of credit card transactions out of which only 492 are frauds (0.172% of the dataset) which implies huge data imbalance.\n\n## Methodology\n1. **Data Exploration**: \n   - Investigated the structure and characteristics of the dataset.\n   - Identified any missing values or duplicates.\n   - Explored the distribution of fraudulent and non-fraudulent transactions.\n\n2. **Data Preprocessing**:\n   - Scaled the features to a uniform range.\n   - Handled class imbalance using SMOTE (Synthetic Minority Over-sampling Technique).\n\n3. **Modeling**:\n   - Supervised machine learning algorithms:\n     - Logistic Regression\n     - Decision Tree Classifier\n     - Random Forest Classifier\n     - Support Vector Machines (SVM)\n     - K-nearest neighbors (kNN)\n     - XGBoost\n   - Unsupervised machine learning algorithms:\n     - One-Class SVM\n     - Local Outlier Factor\n     - DBSCAN\n     - Isolation Forest\n     - K-Means Clustering\n   - Sequentional Neural Network\n   - Tuned hyperparameters using grid search where applicable.\n\n4. **Evaluation**:\n   - Evaluated model performance using metrics such as precision, recall, and F1-score.\n   - Visualized results using confusion matrices and ROC curve.\n   - Compared the performance of different models and techniques.\n\n5. **Conclusion**:\n   - Summarized key findings and insights from the analysis.\n   - Discussed the implications and practical considerations for deploying fraud detection systems in real-world scenarios.\n","metadata":{}},{"cell_type":"markdown","source":"# Import statements","metadata":{}},{"cell_type":"code","source":"# Basic imports\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_theme(rc={'figure.figsize':(12,8)}, palette = \"Purples\")\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\n# Metrics and tools\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import GridSearchCV\n\n# Imports of supervised learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nimport shap\n\n# Imports of unsupervised learning models\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.cluster import KMeans, DBSCAN","metadata":{"execution":{"iopub.status.busy":"2024-06-11T12:41:18.687651Z","iopub.execute_input":"2024-06-11T12:41:18.688104Z","iopub.status.idle":"2024-06-11T12:41:18.70678Z","shell.execute_reply.started":"2024-06-11T12:41:18.688069Z","shell.execute_reply":"2024-06-11T12:41:18.705078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-06-11T12:40:56.639797Z","iopub.execute_input":"2024-06-11T12:40:56.640619Z","iopub.status.idle":"2024-06-11T12:40:56.654337Z","shell.execute_reply.started":"2024-06-11T12:40:56.640581Z","shell.execute_reply":"2024-06-11T12:40:56.652645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data exploration","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-11T12:41:02.038141Z","iopub.execute_input":"2024-06-11T12:41:02.038708Z","iopub.status.idle":"2024-06-11T12:41:06.923228Z","shell.execute_reply.started":"2024-06-11T12:41:02.038652Z","shell.execute_reply":"2024-06-11T12:41:06.921744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicates = df[df.duplicated() == True]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicates.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Class == 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data visualization","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = 'Class', data = df, color='blue')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fraud = df[df['Class'] == 1].describe().T\nnofraud = df[df['Class'] == 0].describe().T\n\n# Selecting only the mean values and renaming the columns\nfraud_mean = fraud[['mean']].rename(columns={'mean': 'Fraud Mean'})\nnofraud_mean = nofraud[['mean']].rename(columns={'mean': 'No Fraud Mean'})\n\ncompare = pd.DataFrame({'Fraud Mean': fraud_mean['Fraud Mean'], 'No Fraud Mean': nofraud_mean['No Fraud Mean']})\n\n# Displaying the mean values of all the features as a DataFrame table\nprint(\"Mean values for Fraud and No Fraud Samples:\")\ncompare\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Defining X and y\n\nX = df.drop('Class', axis=1)\ny = df['Class']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling","metadata":{}},{"cell_type":"code","source":"# Keeps the distribution of the features the same while adjusting their values\n\nscaler = MinMaxScaler().fit(X)\nX = scaler.fit_transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting data making sure the proportion of the classes remain the same in train and test data","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\n\ny.value_counts(), y_train.value_counts(), y_test.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SMOTE","metadata":{}},{"cell_type":"code","source":"# SMOTE to balance the classes\n\nprint(f\"Original class distribution: {Counter(y_train)}\")\n\nsmote = SMOTE(sampling_strategy=0.1, random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X_train, y_train)\nprint(f\"After SMOTE: {Counter(y_resampled)}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting after SMOTE and creating GridSearch subset","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n\nsubset_size = 20000\nX_train_subset,_, y_train_subset, _ = train_test_split(X_train, y_train, train_size=subset_size, random_state=42, stratify=y_train)\n\n# Check proportion of classes\nX_train_subset.shape, y_train_subset.shape, Counter(y_train_subset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining a function to use a GridSearchCV and to evaluate the the models performance\n\ndef grid_search(model, params):\n    grid = GridSearchCV(model, params, scoring= 'f1_macro', cv=5, n_jobs=-1)\n    try: \n        grid = grid.fit(X_train_subset, y_train_subset)\n    except AttributeError:\n        grid = grid.fit_predict(X_train_subset, y_train_subset)\n\n    return grid.best_params_\n\n\ndef evaluate_model(model, **kwargs):\n    results = []\n    try:\n        y_pred = model.predict(X_val)\n    except AttributeError:\n        y_pred = model.fit_predict(X_val)\n\n    if -1 in y_pred:\n        y_pred = np.where(y_pred == -1, 1, 0)\n        \n    print(classification_report(y_val, y_pred))\n    print(confusion_matrix(y_val, y_pred))\n    results.append(classification_report(y_val, y_pred, output_dict=True))\n    results.append(confusion_matrix(y_val, y_pred))\n    return results\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Supervised Methods","metadata":{}},{"cell_type":"markdown","source":"## 1. Logistic Regression\n - Simple and commonly used algorithm for binary classification using sigmoid function that estimates the probability of an outcome based on input features. It's particularly useful for predicting whether an event will happen (e.g., fraud) or not.","metadata":{}},{"cell_type":"code","source":"lr_params = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n    'penalty': ['l1', 'l2', 'elasticnet', 'none']  # Type of regularization\n}\n\nlr = LogisticRegression()\nlr_best_params = grid_search(lr, lr_params)\nprint(lr_best_params)\nlr = LogisticRegression(**lr_best_params)\nlr.fit(X_train, y_train)\nlr_results = evaluate_model(lr)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Decision Tree Classifier\n - Model that splits data into branches based on feature values, making decisions at each node until a final classification is reached. It's intuitive and can handle both numerical and categorical data.","metadata":{}},{"cell_type":"code","source":"dt_params = {\n    'criterion': ['gini', 'entropy'],  # The function to measure the quality of a split\n    'max_depth': [None, 5, 10, 20],  # The maximum depth of the tree\n    'min_samples_split': [2, 5, 10]  # The minimum number of samples required to split an internal node\n}\n\ndt = DecisionTreeClassifier()\ndt_best_params = grid_search(dt, dt_params)\nprint(dt_best_params)\ndt = DecisionTreeClassifier(**dt_best_params)\ndt.fit(X_train, y_train)\ndt_results = evaluate_model(dt)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Random Forest Classifier\n - Ensemble method that builds multiple decision trees and merges them to get a more accurate and stable prediction. It helps reduce overfitting and improves the performance of decision trees.\n\n","metadata":{}},{"cell_type":"code","source":"rfc_params = {\n    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n    'max_depth': [5, 10, 15],  # Maximum depth of the tree\n    'min_samples_split': [2, 5, 10]  # Minimum number of samples required to split an internal node\n}\n\nrfc = RandomForestClassifier()\nrfc_best_params = grid_search(rfc, rfc_params)\nprint(rfc_best_params)\nrfc = RandomForestClassifier(**rfc_best_params)\nrfc.fit(X_train, y_train)\nrfc_results = evaluate_model(rfc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Support Vector Machines (SVM)\n - Powerful classification algorithm that finds the optimal hyperplane to separate classes in the feature space. It works well for high-dimensional data and is effective for both linear and non-linear classifications.","metadata":{}},{"cell_type":"code","source":"'''\nsvm_params = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernel type\n    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n}\n\n\nsvm = SVC()\nsvm_best_params = grid_search(svm, svm_params)\nprint(svm_best_params)\n'''\n\n# To make the code run faster I commented out the grid search, but below are the best parameters it had returned\nsvm = SVC(C=100, gamma='scale', kernel='poly')\nsvm.fit(X_train, y_train)\nsvm_results = evaluate_model(svm)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. K-nearest neighbors (kNN)\n - KNN is a simple, non-parametric algorithm that classifies a data point based on the majority class among its k-nearest neighbors. It’s easy to understand and implement but can be slow for large datasets.","metadata":{}},{"cell_type":"code","source":"knn_params = {\n    'n_neighbors': [5, 10, 15],  # Number of nearest neighbors\n    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  # Algorithm\n}\n\nknn = KNeighborsClassifier()\nknn_best_params = grid_search(knn, knn_params)\nprint(knn_best_params)\nknn = KNeighborsClassifier(**knn_best_params)\nknn.fit(X_train, y_train)\nknn_results = evaluate_model(knn)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. XGBoost\n - XGBoost (eXtreme Gradient Boosting) is an efficient and scalable implementation of gradient boosting for decision trees. It uses advanced regularization to prevent overfitting and can handle missing values. XGBoost is highly popular for its speed, performance, and accuracy, making it ideal for many machine learning tasks, including classification and regression.","metadata":{}},{"cell_type":"code","source":"\nxgb_params = {\n    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n    'max_depth': [5, 10, 15],  # Maximum depth of the tree\n    'min_child_weight': [1, 3, 5]  # Minimum sum of instance weight (hessian) needed in a child    \n}\n\nxgb = XGBClassifier()\nxgb_best_params = grid_search(xgb, xgb_params)\nprint(xgb_best_params)\nxgb = XGBClassifier(**xgb_best_params)\nxgb.fit(X_train, y_train)\nxgb_results = evaluate_model(xgb)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supervised - Predict on unseen data, visualize and compare results of supervised models","metadata":{}},{"cell_type":"code","source":"supervised_models = [lr, dt, rfc, svm, knn, xgb]\nmodel_names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'KNN', 'XGBoost']\n\n# Dictionary to store the results\ntest_data_results = {}\n\n# Train and evaluate the models\nfor model, name in zip(supervised_models, model_names):\n    y_test_pred = model.predict(X_test)\n    if -1 in y_test_pred:\n        y_test_pred = np.where(y_test_pred == -1, 1, 0)\n        \n    test_data_results[name] = {\n        'classification_report': classification_report(y_test, y_test_pred, output_dict=True),\n        'confusion_matrix': confusion_matrix(y_test, y_test_pred)\n    }\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrices","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrices(results):\n    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 15))\n    axes = axes.flatten()\n    \n    for idx, (model, result) in enumerate(results.items()):\n        cm = result['confusion_matrix']\n        sns.heatmap(cm, annot=True, fmt='d', ax=axes[idx], cbar=False, linewidths=1, linecolor='black', xticklabels=['Normal', 'Fraud'], yticklabels=['Normal', 'Fraud'], cmap='Purples')\n        axes[idx].set_title(model)\n        axes[idx].set_xlabel('Predicted labels')\n        axes[idx].set_ylabel('True labels')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Plot the confusion matrices\nplot_confusion_matrices(test_data_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize metrics","metadata":{}},{"cell_type":"code","source":"# Convert the classification report to a DataFrame for visualization\ndata = []\nfor model, metrics in test_data_results.items():\n    report = metrics['classification_report']\n    for label, scores in report.items():\n        if label not in ['accuracy', 'macro avg', 'weighted avg']:\n            data.append([model, label, scores['precision'], scores['recall'], scores['f1-score']])\n\n# Map labels to their corresponding names\nlabel_map = {'0': 'Normal', '1': 'Fraud'}\ndata = [(model, label_map[label], precision, recall, f1) for model, label, precision, recall, f1 in data]\n\n# Define metrics values in percents\ndata = [(model, label, precision * 100, recall * 100, f1 * 100) for model, label, precision, recall, f1 in data]\n\n# Create the DataFrame\ndf = pd.DataFrame(data, columns=['Model', 'Class', 'Precision', 'Recall', 'F1-Score'])\n\n# Plot the results\nfig, axes = plt.subplots(3, 1, figsize=(15, 18))\n\n\n# Function to add labels to all bars\ndef add_labels(ax):\n    for container in ax.containers:\n        ax.bar_label(container, fmt='%.2f%%')\n\nsns.barplot(x='Model', y='Precision',hue='Class', data=df, ax=axes[0], dodge=True, palette='Purples', )\naxes[0].set_title('Precision by Model and Class', fontsize=16, fontweight='bold')\nadd_labels(axes[0])\n\nsns.barplot(x='Model', y='Recall', hue='Class', data=df, ax=axes[1], dodge=True, palette='Purples')\naxes[1].set_title('Recall by Model and Class', fontsize=16, fontweight='bold')\nadd_labels(axes[1])\naxes[1].legend(title='Class', loc='lower right')\n\nsns.barplot(x='Model', y='F1-Score', hue='Class', data=df, ax=axes[2], dodge=True, palette='Purples')\naxes[2].set_title('F1-Score by Model and Class', fontsize=16, fontweight='bold')\nadd_labels(axes[2])\n\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unsupervised Methods","metadata":{}},{"cell_type":"markdown","source":"## 1. One-Class SVM\n - Algorithm that learns a decision function for anomaly detection by finding the boundary that best separates normal data points from outliers in the feature space.","metadata":{}},{"cell_type":"code","source":"svm_params = {\n    'nu': [0.01, 0.05, 0.1, 0.2],  # An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors\n    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernel type\n    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n}\n\nsvm = OneClassSVM()\nsvm_best_params = grid_search(svm, svm_params)\nprint(svm_best_params)\nsvm = OneClassSVM(**svm_best_params)\nsvm.fit(X_train)\nsvm_results = evaluate_model(svm)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Local Outlier Factor\n - LOF identifies anomalies by measuring the local density deviation of a data point relative to its neighbors. Points with significantly lower density than their neighbors are considered outliers.","metadata":{}},{"cell_type":"code","source":"lof = LocalOutlierFactor(algorithm='auto', leaf_size=10, n_neighbors=5)\nlof.fit(X_train)\nlof_results = evaluate_model(lof)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. DBSCAN\n - Clustering algorithm that groups together points that are closely packed, marking points in low-density regions as outliers. It is effective for finding clusters of arbitrary shape and handling noise.","metadata":{}},{"cell_type":"code","source":"dbscan = DBSCAN(eps=0.1, min_samples=5)\ndbscan.fit(X_train)\ndbscan_results = evaluate_model(dbscan)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Isolation Forest\n- Anomaly detection method that isolates observations by randomly selecting a feature and splitting it. Anomalies are isolated quickly, making it effective for identifying outliers in large datasets.","metadata":{}},{"cell_type":"code","source":"iso_for_params = {\n    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n    'max_samples': [0.5, 0.75, 1.0],  # The number of samples to draw from X to train each base estimator\n}\n\niso_for = IsolationForest()\niso_for_best_params = grid_search(iso_for, iso_for_params)\nprint(iso_for_best_params)\niso_for = IsolationForest(**iso_for_best_params)\niso_for.fit(X_train)\niso_for_results = evaluate_model(iso_for)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. K-Mean Clustering\n - K-Means is a popular clustering algorithm that partitions data into k distinct clusters based on feature similarity. Each data point is assigned to the nearest cluster center, and the centers are recalculated iteratively.","metadata":{}},{"cell_type":"code","source":"k_means_params = {\n    'n_clusters': [2, 3, 4, 5],  # The number of clusters\n    'max_iter': [100, 200, 300],  # Maximum number of iterations\n    'tol': [0.001, 0.01, 0.1]  # Tolerance\n}\n\nk_means = KMeans()\nk_means_best_params = grid_search(k_means, k_means_params)\nprint(k_means_best_params)\nk_means = KMeans(**k_means_best_params)\nk_means.fit(X_train)\nk_means_results = evaluate_model(k_means)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unsupervised - Predict on unseen data, visualize and compare results of supervised models","metadata":{}},{"cell_type":"code","source":"unsupervised_models = [svm, lof, dbscan, iso_for, k_means]\nmodel_names = ['SVM', 'LOF', 'DBSCAN', 'Isolation Forest', 'K-Means']\n\n# Dictionary to store the results\nunsupervised_test_results = {}\n\n\n# Train and evaluate the models\nfor model, name in zip(unsupervised_models, model_names):\n    try:\n        y_test_pred = model.predict(X_test)\n    except AttributeError:\n        y_test_pred = model.fit_predict(X_test)\n\n    if -1 in y_test_pred:\n        y_test_pred = np.where(y_test_pred == -1, 1, 0)\n        \n    unsupervised_test_results[name] = {\n        'classification_report': classification_report(y_test, y_test_pred, output_dict=True),\n        'confusion_matrix': confusion_matrix(y_test, y_test_pred)\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrices","metadata":{}},{"cell_type":"code","source":"# Visualize the data\n\nplot_confusion_matrices(unsupervised_test_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize metrics","metadata":{}},{"cell_type":"code","source":"# Convert the classification report to a DataFrame for visualization\ndata = []\nfor model, metrics in unsupervised_test_results.items():\n    report = metrics['classification_report']\n    for label, scores in report.items():\n        if label not in ['accuracy', 'macro avg', 'weighted avg']:\n            data.append([model, label, scores['precision'], scores['recall'], scores['f1-score']])\n\n# Map labels to their corresponding names\nlabel_map = {'0': 'Normal', '1': 'Fraud'}\ndata = [(model, label_map[label], precision, recall, f1) for model, label, precision, recall, f1 in data]\n\n# Define metrics values in percents\ndata = [(model, label, precision * 100, recall * 100, f1 * 100) for model, label, precision, recall, f1 in data]\n\n# Create the DataFrame\ndf = pd.DataFrame(data, columns=['Model', 'Class', 'Precision', 'Recall', 'F1-Score'])\n\n# Plot the results\nfig, axes = plt.subplots(3, 1, figsize=(15, 18))\n\n\n# Function to add labels to all bars\ndef add_labels(ax):\n    for container in ax.containers:\n        ax.bar_label(container, fmt='%.2f%%')\n\nsns.barplot(x='Model', y='Precision',hue='Class', data=df, ax=axes[0], dodge=True, palette='Purples', )\naxes[0].set_title('Precision by Model and Class', fontsize=16, fontweight='bold')\nadd_labels(axes[0])\n\nsns.barplot(x='Model', y='Recall', hue='Class', data=df, ax=axes[1], dodge=True, palette='Purples')\naxes[1].set_title('Recall by Model and Class', fontsize=16, fontweight='bold')\nadd_labels(axes[1])\n\nsns.barplot(x='Model', y='F1-Score', hue='Class', data=df, ax=axes[2], dodge=True, palette='Purples')\naxes[2].set_title('F1-Score by Model and Class', fontsize=16, fontweight='bold')\nadd_labels(axes[2])\n\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural networks and supervised methods","metadata":{}},{"cell_type":"markdown","source":"## Neural Network","metadata":{}},{"cell_type":"code","source":"# Define the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Adding callbacks\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)\n\n# Training\nhistory = model.fit(X_train,y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val),\n                    callbacks=[early_stopping, reduce_lr])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\n# Step 1: Generate predictions\ny_pred_proba = model.predict(X_val).ravel()\n\n# Step 2: Calculate ROC curve\nfpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n\n# Step 3: Plot ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % auc(fpr, tpr))\nplt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guessing')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.grid(True)\nplt.show()\n\n# Step 4: Calculate AUC-ROC\nauc_score = auc(fpr, tpr)\nprint(\"AUC-ROC Score:\", auc_score)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate on test data using calculated threshold\ny_pred = (model.predict(X_test) > 0.983).astype(int)\n\nneural_test_data_results = {}\n# Calculate classification report\nneural_test_data_results['ANN'] = {\n    'classification_report': classification_report(y_test, y_pred, output_dict=True),\n    'confusion_matrix': confusion_matrix(y_test, y_pred)\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(neural_test_data_results['ANN']['confusion_matrix'], annot=True, fmt='d', cmap='Purples', linewidths=1, linecolor='black', xticklabels=['Normal', 'Fraud'], yticklabels=['Normal', 'Fraud'], cbar=False)\nplt.title('ANN Confusion Matrix', fontsize=16, fontweight='bold')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"Based on the analysis, both XGBoost, Random Forest and Neural Network models performed exceptionally well in detecting credit card fraud. However, XGBoost and Random Forest are more interpretable and transparent, providing clear feature importances and decision pathways. This transparency is crucial for explaining flagged transactions.\n\nWhile Neural Networks demonstrated strong predictive power, their complexity and black-box nature pose challenges in explaining decisions to stakeholders.\n\nTherefore, for practical deployment and interpretability in credit card fraud detection, Random Forest or XGBoost models are the preferred choices.","metadata":{}},{"cell_type":"markdown","source":"## Random Forest Classifier parameter tuning","metadata":{}},{"cell_type":"code","source":"# Try to improve model performace of Random Forest Classifier adjusting Class weights\n\n# Define class weights\nclass_weights = {0: 1, 1: 10}  # Adjust the weights as needed\n\n# Train the model with adjusted class weights\nrfc = RandomForestClassifier(**rfc_best_params, class_weight=class_weights)\nrfc.fit(X_train, y_train)\n\n# Evaluate the model on validation data\nrfc_results = evaluate_model(rfc)\n\n# Evaluate the model on test data\ny_pred = rfc.predict(X_test)\nrfc_test_data_results = {}\nrfc_test_data_results['Random Forest'] = {\n    'classification_report': classification_report(y_test, y_pred, output_dict=True),\n    'confusion_matrix': confusion_matrix(y_test, y_pred)\n}\n\n\n# Plot confusion matrix\nsns.heatmap(rfc_test_data_results['Random Forest']['confusion_matrix'], annot=True, fmt='d', cmap='Purples', linewidths=1, linecolor='black', xticklabels=['Normal', 'Fraud'], yticklabels=['Normal', 'Fraud'], cbar=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classifier Feature importance","metadata":{}},{"cell_type":"code","source":"feature_importances = rfc.feature_importances_\n\n# Sort the feature importances in descending order\nsorted_idx = np.argsort(feature_importances)[::-1]\nsorted_importances = feature_importances[sorted_idx]\n\n# Get the feature names\nfeature_names = df.columns[:-1]\n\n# Plot the feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(range(X_train.shape[1]), sorted_importances, align='center', color='purple')\nplt.xticks(range(X_train.shape[1]), feature_names[sorted_idx], rotation=90)\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.title('Feature Importances')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost SHAP","metadata":{}},{"cell_type":"code","source":"# Create a SHAP explainer object using your trained XGBoost model\nexplainer = shap.Explainer(xgb)\n\n# Calculate SHAP values for all features using the validation data\nshap_values = explainer.shap_values(X_val)\n\n# Plot the SHAP summary plot\nshap.summary_plot(shap_values, X_val, plot_type=\"bar\", color=\"purple\")","metadata":{},"execution_count":null,"outputs":[]}]}